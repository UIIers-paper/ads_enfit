{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ads_enfit\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ads_enfit\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/ads_enfit\n",
      "d:/ads_enfit/prj\n",
      "d:/ads_enfit/data/energy/enefit\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'enefit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32md:\\ads_enfit\\config\\config.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m         sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, lib)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# np.set_printoptions(precision=2, suppress=True, formatter={'float': '{: 0.4f}'.format}, linewidth=1000)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01menefit\u001b[39;00m\n\u001b[0;32m     18\u001b[0m env \u001b[38;5;241m=\u001b[39m enefit\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[0;32m     19\u001b[0m iter_test \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39miter_test()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'enefit'"
     ]
    }
   ],
   "source": [
    "from libs.common import *\n",
    "from config.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'enefit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01menefit\u001b[39;00m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m enefit\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[0;32m      3\u001b[0m iter_test \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39miter_test()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'enefit'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define important columns\n",
    "data_cols = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\n",
    "client_cols = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\n",
    "gas_prices_cols = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\n",
    "electricity_prices_cols = ['forecast_date', 'euros_per_mwh']\n",
    "forecast_weather_cols = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\n",
    "historical_weather_cols = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\n",
    "location_cols = ['longitude', 'latitude', 'county']\n",
    "target_cols = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n",
    "\n",
    "root=data_dir\n",
    "## Importing only specified columns\n",
    "df_data = pl.read_csv(os.path.join(root, \"train.csv\"), columns=data_cols, try_parse_dates=True)\n",
    "df_client = pl.read_csv(os.path.join(root, \"client.csv\"), columns=client_cols, try_parse_dates=True)\n",
    "df_gas_prices = pl.read_csv(os.path.join(root, \"gas_prices.csv\"), columns=gas_prices_cols, try_parse_dates=True)\n",
    "df_electricity_prices = pl.read_csv(os.path.join(root, \"electricity_prices.csv\"), columns=electricity_prices_cols, try_parse_dates=True)\n",
    "df_forecast_weather = pl.read_csv(os.path.join(root, \"forecast_weather.csv\"), columns=forecast_weather_cols, try_parse_dates=True)\n",
    "df_historical_weather = pl.read_csv(os.path.join(root, \"historical_weather.csv\"), columns=historical_weather_cols, try_parse_dates=True)\n",
    "df_weather_station_to_county_mapping = pl.read_csv(os.path.join(root, \"weather_station_to_county_mapping.csv\"), columns=location_cols, try_parse_dates=True)\n",
    "df_target = df_data.select(target_cols)\n",
    "\n",
    "## Prepare schema for api submission\n",
    "schema_data = df_data.schema\n",
    "schema_client = df_client.schema\n",
    "schema_gas  = df_gas_prices.schema\n",
    "schema_electricity = df_electricity_prices.schema\n",
    "schema_forecast = df_forecast_weather.schema\n",
    "schema_historical = df_historical_weather.schema\n",
    "schema_target = df_target.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df_data, df_client, df_gas_prices, df_electricity_prices, df_forecast_weather, df_historical_weather, df_weather_station_to_county_mapping, df_target):\n",
    "    df_data = (\n",
    "        df_data.with_columns(pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),)\n",
    "    )\n",
    "    \n",
    "    df_gas_prices = (\n",
    "        df_gas_prices.rename({\"forecast_date\": \"date\"})\n",
    "    )\n",
    "    \n",
    "    df_electricity_prices = (\n",
    "        df_electricity_prices.rename({\"forecast_date\": \"datetime\"})\n",
    "    )\n",
    "    \n",
    "    df_weather_station_to_county_mapping = (\n",
    "        df_weather_station_to_county_mapping.with_columns(pl.col(\"latitude\").cast(pl.datatypes.Float32),pl.col(\"longitude\").cast(pl.datatypes.Float32))\n",
    "    )\n",
    "    \n",
    "    # sum of all product_type targets related to [\"datetime\", \"county\", \"is_business\", \"is_consumption\"]\n",
    "    df_target_all_type_sum = (\n",
    "        df_target.group_by([\"datetime\", \"county\", \"is_business\", \"is_consumption\"]).sum().drop(\"product_type\")\n",
    "    )\n",
    "    \n",
    "    df_forecast_weather = (\n",
    "        df_forecast_weather.rename({\"forecast_datetime\": \"datetime\"}).filter(pl.col(\"hours_ahead\") >= 24) # we don't need forecast for today\n",
    "        .with_columns(pl.col(\"latitude\").cast(pl.datatypes.Float32),pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "            # datetime for forecast in a different timezone\n",
    "            pl.col('datetime').dt.replace_time_zone(None).cast(pl.Datetime(\"us\")),\n",
    "        )\n",
    "        .join(df_weather_station_to_county_mapping, how=\"left\", on=[\"longitude\", \"latitude\"]).drop(\"longitude\", \"latitude\")\n",
    "    )\n",
    "    \n",
    "    df_historical_weather = (\n",
    "        df_historical_weather\n",
    "        .with_columns(pl.col(\"latitude\").cast(pl.datatypes.Float32),pl.col(\"longitude\").cast(pl.datatypes.Float32),\n",
    "        )\n",
    "        .join(df_weather_station_to_county_mapping, how=\"left\", on=[\"longitude\", \"latitude\"]).drop(\"longitude\", \"latitude\")\n",
    "    )\n",
    "    \n",
    "    # creating average forecast characteristics for all weather stations\n",
    "    df_forecast_weather_date = (\n",
    "        df_forecast_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "    )\n",
    "    \n",
    "    # creating average forecast characteristics for weather stations related to county\n",
    "    df_forecast_weather_local = (\n",
    "        df_forecast_weather.filter(pl.col(\"county\").is_not_null()).group_by(\"county\", \"datetime\").mean()\n",
    "    )\n",
    "    \n",
    "    # creating average historical characteristics for all weather stations\n",
    "    df_historical_weather_date = (\n",
    "        df_historical_weather.group_by(\"datetime\").mean().drop(\"county\")\n",
    "    )\n",
    "    \n",
    "    # creating average historical characteristics for weather stations related to county\n",
    "    df_historical_weather_local = (\n",
    "        df_historical_weather.filter(pl.col(\"county\").is_not_null()).group_by(\"county\", \"datetime\").mean()\n",
    "    )\n",
    "    \n",
    "    df_data = (\n",
    "        df_data\n",
    "        # pl.duration(days=1) shifts datetime to join lag features (usually we join last available values)\n",
    "        .join(df_gas_prices.with_columns((pl.col(\"date\") + pl.duration(days=1)).cast(pl.Date)), on=\"date\", how=\"left\")\n",
    "        .join(df_client.with_columns((pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)), on=[\"county\", \"is_business\", \"product_type\", \"date\"], how=\"left\")\n",
    "        .join(df_electricity_prices.with_columns(pl.col(\"datetime\") + pl.duration(days=1)), on=\"datetime\", how=\"left\")\n",
    "        \n",
    "        # lag forecast_weather features (24 hours * days)\n",
    "        .join(df_forecast_weather_date, on=\"datetime\", how=\"left\", suffix=\"_fd\")\n",
    "        .join(df_forecast_weather_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl\")\n",
    "        .join(df_forecast_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_fd_7d\")\n",
    "        .join(df_forecast_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl_7d\")\n",
    "\n",
    "        # lag historical_weather features (24 hours * days)\n",
    "        .join(df_historical_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=2)), on=\"datetime\", how=\"left\", suffix=\"_hd_2d\")\n",
    "        .join(df_historical_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=2)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_2d\")\n",
    "        .join(df_historical_weather_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_hd_7d\")\n",
    "        .join(df_historical_weather_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_7d\")\n",
    "        \n",
    "        # lag target features (24 hours * days)\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_1\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=4)).rename({\"target\": \"target_3\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=5)).rename({\"target\": \"target_4\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=6)).rename({\"target\": \"target_5\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n",
    "        \n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_1\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        .join(df_target_all_type_sum.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"is_consumption\", \"datetime\"], suffix=\"_all_type_sum\", how=\"left\")\n",
    "        \n",
    "        \n",
    "        .with_columns(\n",
    "            pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n",
    "            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n",
    "            pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.concat_str(\"county\", \"is_business\", \"product_type\", \"is_consumption\", separator=\"_\").alias(\"segment\"),\n",
    "        )\n",
    "        # cyclical features encoding https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca\n",
    "        .with_columns(\n",
    "            (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n",
    "            (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n",
    "            (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n",
    "            (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(pl.Float64).cast(pl.Float32),\n",
    "        )\n",
    "        \n",
    "        .drop(\"datetime\", \"hour\", \"dayofyear\")\n",
    "    )\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function defined for merging dataframes with the row_id as unique identifier\n",
    "def to_pandas(X, y=None):\n",
    "    cat_cols = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"segment\"]\n",
    "    \n",
    "    if y is not None:\n",
    "        df = pd.concat([X.to_pandas(), y.to_pandas()], axis=1)\n",
    "    else:\n",
    "        df = X.to_pandas()    \n",
    "    \n",
    "    df = df.set_index(\"row_id\")\n",
    "    df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "    \n",
    "    df[\"target_mean\"] = df[[f\"target_{i}\" for i in range(1, 7)]].mean(1)\n",
    "    df[\"target_std\"] = df[[f\"target_{i}\" for i in range(1, 7)]].std(1)\n",
    "    df[\"target_ratio\"] = df[\"target_6\"] / (df[\"target_7\"] + 1e-3)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
