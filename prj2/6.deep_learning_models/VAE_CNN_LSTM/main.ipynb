{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-tabnet) (4.66.2)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch-tabnet) (2.2.1)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.14.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (23.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (2.2.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (0.11.6)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pytorch_lightning) (1.4.0.post0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (69.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.1.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->pytorch_lightning) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=2.0.0->pytorch_lightning) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pytorch-tabnet\n",
    "!python -m pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\lenovo\\_netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login cccce13d087a6622943e34e917c915d3f1c12906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import with OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\OneDrive - Cong ty co phan Format Vietnam JSC\\Desktop\\ads_enfit\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = os.path.join(root_dir, 'exps/exp2')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\OneDrive - Cong ty co phan Format Vietnam JSC\\Desktop\\ads_enfit\\exps/exp2\n"
     ]
    }
   ],
   "source": [
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library/framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/lenovo/OneDrive - Cong ty co phan Format Vietnam JSC/Desktop/ads_enfit\n"
     ]
    }
   ],
   "source": [
    "from libs.common import *\n",
    "from config.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(f'{save_dir}/X_train.csv', index_col=None)\n",
    "X_valid=pd.read_csv(f'{save_dir}/X_valid.csv', index_col=None)\n",
    "y_train=pd.read_csv(f'{save_dir}/y_train.csv', index_col=None)\n",
    "y_valid=pd.read_csv(f'{save_dir}/y_valid.csv', index_col=None)\n",
    "X_test = pd.read_csv(f'{save_dir}/X_test.csv', index_col=None)\n",
    "y_test = pd.read_csv(f'{save_dir}/y_test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=[\"Unnamed: 0\"])\n",
    "X_valid = X_valid.drop(columns=[\"Unnamed: 0\"])\n",
    "y_train = y_train.drop(columns=[\"Unnamed: 0\"])\n",
    "y_valid = y_valid.drop(columns=[\"Unnamed: 0\"])\n",
    "X_test = X_test.drop(columns=[\"Unnamed: 0\"])\n",
    "y_test = y_test.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "pretrain_dataset = TabularDataset(X_train, X_train)\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "valid_dataset = TabularDataset(X_valid, y_valid)\n",
    "test_dataset = TabularDataset(X_test, y_test)\n",
    "\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataset = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain with basic AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a long time to converge, move to the pretrain with Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PretrainedModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.fc4 = nn.Linear(64, 128)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(128, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.dropout5 = nn.Dropout(0.3)\n",
    "        self.fc6 = nn.Linear(256, input_dim)  # Changed output dimension to match input dimension\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        x = torch.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = PretrainedModel(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 50, Loss: 6781848611.84\n",
      "Epoch 1, Batch 100, Loss: 6804729610.24\n",
      "Epoch 1, Batch 150, Loss: 6652121907.2\n",
      "Epoch 1, Batch 200, Loss: 6851479162.88\n",
      "Epoch 1, Batch 250, Loss: 6749243187.2\n",
      "Epoch 1, Batch 300, Loss: 6706622443.52\n",
      "Epoch 1, Batch 350, Loss: 6663213056.0\n",
      "Epoch 1, Batch 400, Loss: 6733930905.6\n",
      "Epoch 1, Batch 450, Loss: 6683670067.2\n",
      "Epoch 1, Batch 500, Loss: 6756838748.16\n",
      "Epoch 1, Batch 550, Loss: 6818785720.32\n",
      "Epoch 1, Batch 600, Loss: 6900345098.24\n",
      "Epoch 1, Batch 650, Loss: 6709935626.24\n",
      "Epoch 1, Batch 700, Loss: 6629738956.8\n",
      "Epoch 1, Batch 750, Loss: 6769588695.04\n",
      "Epoch 1, Batch 800, Loss: 6847376936.96\n",
      "Epoch 1, Batch 850, Loss: 6664008089.6\n",
      "Epoch 1, Batch 900, Loss: 6657049999.36\n",
      "Epoch 1, Batch 950, Loss: 6627681761.28\n",
      "Epoch 1, Batch 1000, Loss: 6678654177.28\n",
      "Epoch 1, Batch 1050, Loss: 6625803827.2\n",
      "Epoch 1, Batch 1100, Loss: 6756674416.64\n",
      "Epoch 1, Batch 1150, Loss: 6828769505.28\n",
      "Epoch 1, Batch 1200, Loss: 6768721971.2\n",
      "Epoch 1, Batch 1250, Loss: 6735470817.28\n",
      "Epoch 1, Batch 1300, Loss: 6685290639.36\n",
      "Epoch 1, Batch 1350, Loss: 6625994076.16\n",
      "Epoch 1, Batch 1400, Loss: 6552452331.52\n",
      "Epoch 1, Batch 1450, Loss: 6704890490.88\n",
      "Epoch 1, Batch 1500, Loss: 6771128637.44\n",
      "Epoch 1, Batch 1550, Loss: 6709220567.04\n",
      "Epoch 1, Batch 1600, Loss: 6821734010.88\n",
      "Epoch 1, Batch 1650, Loss: 6709894942.72\n",
      "Epoch 1, Batch 1700, Loss: 6782047989.76\n",
      "Epoch 1, Batch 1750, Loss: 6760882995.2\n",
      "Epoch 1, Batch 1800, Loss: 6674297057.28\n",
      "Epoch 1, Batch 1850, Loss: 6682447831.04\n",
      "Epoch 1, Batch 1900, Loss: 6634332190.72\n",
      "Epoch 1, Batch 1950, Loss: 6590053806.08\n",
      "Epoch 1, Batch 2000, Loss: 6485045053.44\n",
      "Epoch 1, Batch 2050, Loss: 6472566497.28\n",
      "Epoch 1, Batch 2100, Loss: 6728066529.28\n",
      "Epoch 1, Batch 2150, Loss: 6718728458.24\n",
      "Epoch 1, Batch 2200, Loss: 6709489971.2\n",
      "Epoch 1, Batch 2250, Loss: 6751703121.92\n",
      "Epoch 1, Batch 2300, Loss: 6578519808.0\n",
      "Epoch 1, Batch 2350, Loss: 6607974123.52\n",
      "Epoch 1, Batch 2400, Loss: 6777830942.72\n",
      "Epoch 1, Batch 2450, Loss: 6674499983.36\n",
      "Epoch 1, Batch 2500, Loss: 6756309411.84\n",
      "Epoch 1, Batch 2550, Loss: 6626217492.48\n",
      "Epoch 1, Batch 2600, Loss: 6685367080.96\n",
      "Epoch 1, Batch 2650, Loss: 6794027714.56\n",
      "Epoch 1, Batch 2700, Loss: 6539813550.08\n",
      "Epoch 1, Batch 2750, Loss: 6634840832.0\n",
      "Epoch 1, Batch 2800, Loss: 6519936522.24\n",
      "Epoch 1, Batch 2850, Loss: 6609160519.68\n",
      "Epoch 1, Batch 2900, Loss: 6879047680.0\n",
      "Epoch 1, Batch 2950, Loss: 6783059159.04\n",
      "Epoch 1, Batch 3000, Loss: 6944772014.08\n",
      "Epoch 1, Batch 3050, Loss: 6525820569.6\n",
      "Epoch 1, Batch 3100, Loss: 6678926827.52\n",
      "Epoch 1, Batch 3150, Loss: 6756496936.96\n",
      "Epoch 1, Batch 3200, Loss: 6573296691.2\n",
      "Epoch 1, Batch 3250, Loss: 6567310356.48\n",
      "Epoch 1, Batch 3300, Loss: 6568850780.16\n",
      "Epoch 1, Batch 3350, Loss: 6662038292.48\n",
      "Epoch 1, Batch 3400, Loss: 6798142136.32\n",
      "Epoch 1, Batch 3450, Loss: 6518063564.8\n",
      "Epoch 1, Batch 3500, Loss: 6594934804.48\n",
      "Epoch 1, Batch 3550, Loss: 6648963102.72\n",
      "Epoch 1, Batch 3600, Loss: 6716227010.56\n",
      "Epoch 1, Batch 3650, Loss: 6652597903.36\n",
      "Epoch 1, Batch 3700, Loss: 6604115732.48\n",
      "Epoch 1, Batch 3750, Loss: 6698911723.52\n",
      "Epoch 1, Batch 3800, Loss: 6659379240.96\n",
      "Epoch 1, Batch 3850, Loss: 6661551800.32\n",
      "Epoch 1, Batch 3900, Loss: 6574124851.2\n",
      "Epoch 1, Batch 3950, Loss: 6534405304.32\n",
      "Epoch 1, Batch 4000, Loss: 6619882516.48\n",
      "Epoch 1, Batch 4050, Loss: 6525049221.12\n",
      "Epoch 1, Batch 4100, Loss: 6514124564.48\n",
      "Epoch 1, Batch 4150, Loss: 6564852920.32\n",
      "Epoch 1, Batch 4200, Loss: 6681900574.72\n",
      "Epoch 1, Batch 4250, Loss: 6456940769.28\n",
      "Epoch 1, Batch 4300, Loss: 6509501788.16\n",
      "Epoch 1, Batch 4350, Loss: 6567283712.0\n",
      "Epoch 1, Batch 4400, Loss: 6669879111.68\n",
      "Epoch 1, Batch 4450, Loss: 6510027765.76\n",
      "Epoch 1, Batch 4500, Loss: 6689603563.52\n",
      "Epoch 1, Batch 4550, Loss: 6639019898.88\n",
      "Epoch 1, Batch 4600, Loss: 6419393136.64\n",
      "Epoch 1, Batch 4650, Loss: 6511545405.44\n",
      "Epoch 1, Batch 4700, Loss: 6398525020.16\n",
      "Epoch 1, Batch 4750, Loss: 6571347660.8\n",
      "Epoch 1, Batch 4800, Loss: 6688417658.88\n",
      "Epoch 1, Batch 4850, Loss: 6516850391.04\n",
      "Epoch 1, Batch 4900, Loss: 6371301355.52\n",
      "Epoch 1, Batch 4950, Loss: 6383022653.44\n",
      "Epoch 1, Batch 5000, Loss: 6458582097.92\n",
      "Epoch 1, Batch 5050, Loss: 6669033553.92\n",
      "Epoch 1, Batch 5100, Loss: 6323227914.24\n",
      "Epoch 1, Batch 5150, Loss: 6598775285.76\n",
      "Epoch 1, Batch 5200, Loss: 6441777448.96\n",
      "Epoch 1, Batch 5250, Loss: 6443889551.36\n",
      "Epoch 1, Batch 5300, Loss: 6365429821.44\n",
      "Epoch 1, Batch 5350, Loss: 6508360509.44\n",
      "Epoch 1, Batch 5400, Loss: 6469995397.12\n",
      "Epoch 1, Batch 5450, Loss: 6502660720.64\n",
      "Epoch 1, Batch 5500, Loss: 6374186506.24\n",
      "Epoch 1, Batch 5550, Loss: 6430693693.44\n",
      "Epoch 1, Batch 5600, Loss: 6564706109.44\n",
      "Epoch 1, Batch 5650, Loss: 6446583408.64\n",
      "Epoch 1, Batch 5700, Loss: 6406598922.24\n",
      "Epoch 1, Batch 5750, Loss: 6579371304.96\n",
      "Epoch 1, Batch 5800, Loss: 6597339473.92\n",
      "Epoch 1, Batch 5850, Loss: 6537028730.88\n",
      "Epoch 1, Batch 5900, Loss: 6425944586.24\n",
      "Epoch 1, Batch 5950, Loss: 6557042606.08\n",
      "Epoch 1, Batch 6000, Loss: 6444327639.04\n",
      "Epoch 1, Batch 6050, Loss: 6594693181.44\n",
      "Epoch 1, Batch 6100, Loss: 6328081356.8\n",
      "Epoch 1, Batch 6150, Loss: 6494748385.28\n",
      "Epoch 1, Batch 6200, Loss: 6551051653.12\n",
      "Epoch 1, Batch 6250, Loss: 6402931097.6\n",
      "Epoch 1, Batch 6300, Loss: 6265145118.72\n",
      "Epoch 1, Batch 6350, Loss: 6262756208.64\n",
      "Epoch 1, Batch 6400, Loss: 6430605342.72\n",
      "Epoch 1, Batch 6450, Loss: 6353284864.0\n",
      "Epoch 1, Batch 6500, Loss: 6503052738.56\n",
      "Epoch 1, Batch 6550, Loss: 6362193530.88\n",
      "Epoch 1, Batch 6600, Loss: 6359773675.52\n",
      "Epoch 1, Batch 6650, Loss: 6412522547.2\n",
      "Epoch 1, Batch 6700, Loss: 6359539215.36\n",
      "Epoch 1, Batch 6750, Loss: 6356897331.2\n",
      "Epoch 1, Batch 6800, Loss: 6433498572.8\n",
      "Epoch 1, Batch 6850, Loss: 6195713843.2\n",
      "Epoch 1, Batch 6900, Loss: 6359498762.24\n",
      "Epoch 1, Batch 6950, Loss: 6372730757.12\n",
      "Epoch 1, Batch 7000, Loss: 6477058488.32\n",
      "Epoch 1, Batch 7050, Loss: 6264229601.28\n",
      "Epoch 1, Batch 7100, Loss: 6354745159.68\n",
      "Epoch 1, Batch 7150, Loss: 6361293240.32\n",
      "Epoch 1, Batch 7200, Loss: 6304185932.8\n",
      "Epoch 1, Batch 7250, Loss: 6491465185.28\n",
      "Epoch 1, Batch 7300, Loss: 6307116359.68\n",
      "Epoch 1, Batch 7350, Loss: 6454702438.4\n",
      "Epoch 1, Batch 7400, Loss: 6335461068.8\n",
      "Epoch 1, Batch 7450, Loss: 6461381642.24\n",
      "Epoch 1, Batch 7500, Loss: 6307802152.96\n",
      "Epoch 1, Batch 7550, Loss: 6384265768.96\n",
      "Epoch 1, Batch 7600, Loss: 6089795962.88\n",
      "Epoch 1, Batch 7650, Loss: 6377884026.88\n",
      "Epoch 1, Batch 7700, Loss: 6528864593.92\n",
      "Epoch 1, Batch 7750, Loss: 6245027205.12\n",
      "Epoch 1, Batch 7800, Loss: 6351278356.48\n",
      "Epoch 1, Batch 7850, Loss: 6222862653.44\n",
      "Epoch 1, Batch 7900, Loss: 6362237184.0\n",
      "Epoch 1, Batch 7950, Loss: 6192351447.04\n",
      "Epoch 1, Batch 8000, Loss: 6361808793.6\n",
      "Epoch 1, Batch 8050, Loss: 6318979389.44\n",
      "Epoch 1, Batch 8100, Loss: 6136547747.84\n",
      "Epoch 1, Batch 8150, Loss: 6026646220.8\n",
      "Epoch 1, Batch 8200, Loss: 6221926492.16\n",
      "Epoch 1, Batch 8250, Loss: 6032775777.28\n",
      "Epoch 1, Batch 8300, Loss: 6189922457.6\n",
      "Epoch 1, Batch 8350, Loss: 6052585825.28\n",
      "Epoch 1, Batch 8400, Loss: 6223239546.88\n",
      "Epoch 1, Batch 8450, Loss: 6147096883.2\n",
      "Epoch 1, Batch 8500, Loss: 6173430169.6\n",
      "Epoch 1, Batch 8550, Loss: 6010391818.24\n",
      "Epoch 1, Batch 8600, Loss: 6054823372.8\n",
      "Epoch 1, Batch 8650, Loss: 6191774146.56\n",
      "Epoch 1, Batch 8700, Loss: 6062185379.84\n",
      "Epoch 1, Batch 8750, Loss: 6079316367.36\n",
      "Epoch 1, Batch 8800, Loss: 6294748231.68\n",
      "Epoch 1, Batch 8850, Loss: 6079950668.8\n",
      "Epoch 1, Batch 8900, Loss: 6245494456.32\n",
      "Epoch 1, Batch 8950, Loss: 6138028011.52\n",
      "Epoch 1, Batch 9000, Loss: 6294675691.52\n",
      "Epoch 1, Batch 9050, Loss: 5974099348.48\n",
      "Epoch 1, Batch 9100, Loss: 6036630784.0\n",
      "Epoch 1, Batch 9150, Loss: 6162492129.28\n",
      "Epoch 1, Batch 9200, Loss: 6291649351.68\n",
      "Epoch 1, Batch 9250, Loss: 6185601034.24\n",
      "Epoch 1, Batch 9300, Loss: 6230523412.48\n",
      "Epoch 1, Batch 9350, Loss: 6131993681.92\n",
      "Epoch 1, Batch 9400, Loss: 6114022553.6\n",
      "Epoch 1, Batch 9450, Loss: 6094641920.0\n",
      "Epoch 1, Batch 9500, Loss: 6023225190.4\n",
      "Epoch 1, Batch 9550, Loss: 6008415682.56\n",
      "Epoch 1, Batch 9600, Loss: 6024120970.24\n",
      "Epoch 1, Batch 9650, Loss: 6224772423.68\n",
      "Epoch 1, Batch 9700, Loss: 6285719828.48\n",
      "Epoch 1, Batch 9750, Loss: 6004125655.04\n",
      "Epoch 1, Batch 9800, Loss: 6164694732.8\n",
      "Epoch 1, Batch 9850, Loss: 6015405230.08\n",
      "Epoch 1, Batch 9900, Loss: 5904689203.2\n",
      "Epoch 1, Batch 9950, Loss: 5997366307.84\n",
      "Epoch 1, Batch 10000, Loss: 6059759185.92\n",
      "Epoch 1, Batch 10050, Loss: 6006666260.48\n",
      "Epoch 1, Batch 10100, Loss: 5963860561.92\n",
      "Epoch 1, Batch 10150, Loss: 5982590003.2\n",
      "Epoch 1, Batch 10200, Loss: 5944478023.68\n",
      "Epoch 1, Batch 10250, Loss: 6126411264.0\n",
      "Epoch 1, Batch 10300, Loss: 6094357647.36\n",
      "Epoch 1, Batch 10350, Loss: 5911658501.12\n",
      "Epoch 1, Batch 10400, Loss: 6026220892.16\n",
      "Epoch 1, Batch 10450, Loss: 6093538713.6\n",
      "Epoch 1, Batch 10500, Loss: 5934130022.4\n",
      "Epoch 1, Batch 10550, Loss: 6144593295.36\n",
      "Epoch 1, Batch 10600, Loss: 5985675612.16\n",
      "Epoch 1, Batch 10650, Loss: 6012216023.04\n",
      "Epoch 1, Batch 10700, Loss: 5887924346.88\n",
      "Epoch 1, Batch 10750, Loss: 5957549900.8\n",
      "Epoch 1, Batch 10800, Loss: 6032537559.04\n",
      "Epoch 1, Batch 10850, Loss: 5930260234.24\n",
      "Epoch 1, Batch 10900, Loss: 5815072824.32\n",
      "Epoch 1, Batch 10950, Loss: 5837432453.12\n",
      "Epoch 1, Batch 11000, Loss: 5919757998.08\n",
      "Epoch 1, Batch 11050, Loss: 5982872320.0\n",
      "Epoch 1, Batch 11100, Loss: 5823736340.48\n",
      "Epoch 1, Batch 11150, Loss: 5877238773.76\n",
      "Epoch 1, Batch 11200, Loss: 5675077800.96\n",
      "Epoch 1, Batch 11250, Loss: 5877338844.16\n",
      "Epoch 1, Batch 11300, Loss: 5843604275.2\n",
      "Epoch 1, Batch 11350, Loss: 5847193927.68\n",
      "Epoch 1, Batch 11400, Loss: 6048507269.12\n",
      "Epoch 1, Batch 11450, Loss: 5788122004.48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mtrain_pretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 10\u001b[0m, in \u001b[0;36mtrain_pretrain\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     recon_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(recon_batch, data)\n\u001b[0;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[39], line 32\u001b[0m, in \u001b[0;36mPretrainedModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn5(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc5(x)))\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout5(x)\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_pretrain(model, device, train_loader, optimizer, epoch):\n",
    "    model.to(device)\n",
    "    #train_loader.dataset.to(device)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch = model(data)\n",
    "        loss = F.mse_loss(recon_batch, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (batch_idx + 1) % 50 == 0:\n",
    "            print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {total_loss / 50}')\n",
    "            total_loss = 0\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# pretrain_loader.dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_pretrain(model, device, pretrain_loader, optimizer, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain with Tabnet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 169515.26133| val_0_unsup_loss_numpy: 480.5047607421875|  0:04:01s\n",
      "epoch 1  | loss: 217.07925| val_0_unsup_loss_numpy: 447.44287109375|  0:08:38s\n",
      "epoch 2  | loss: 205.98656| val_0_unsup_loss_numpy: 427.7922668457031|  0:13:03s\n",
      "epoch 3  | loss: 207.85633| val_0_unsup_loss_numpy: 396.24853515625|  0:16:57s\n",
      "epoch 4  | loss: 198.49121| val_0_unsup_loss_numpy: 399.6509704589844|  0:21:40s\n",
      "epoch 5  | loss: 188.54674| val_0_unsup_loss_numpy: 367.6967468261719|  0:26:20s\n",
      "epoch 6  | loss: 175.31442| val_0_unsup_loss_numpy: 357.1885986328125|  0:30:22s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m unsupervised_model \u001b[38;5;241m=\u001b[39m TabNetPretrainer(\n\u001b[0;32m      2\u001b[0m     optimizer_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam,\n\u001b[0;32m      3\u001b[0m     optimizer_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-2\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     device_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[43munsupervised_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretraining_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m unsupervised_model\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtabnet_pretrainer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\pretraining.py:155\u001b[0m, in \u001b[0;36mTabNetPretrainer.fit\u001b[1;34m(self, X_train, eval_set, eval_name, loss_fn, pretraining_ratio, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, warm_start)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\pretraining.py:288\u001b[0m, in \u001b[0;36mTabNetPretrainer._train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, X \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[1;32m--> 288\u001b[0m     batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[0;32m    292\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\pretraining.py:320\u001b[0m, in \u001b[0;36mTabNetPretrainer._train_batch\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m    318\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m output, embedded_x, obf_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(output, embedded_x, obf_vars)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# Perform backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:386\u001b[0m, in \u001b[0;36mTabNetPretraining.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# set prior of encoder with obfuscated groups\u001b[39;00m\n\u001b[0;32m    385\u001b[0m prior \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m obfuscated_groups\n\u001b[1;32m--> 386\u001b[0m steps_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(steps_out)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, embedded_x, obfuscated_vars\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:181\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[1;34m(self, x, prior)\u001b[0m\n\u001b[0;32m    179\u001b[0m M_feature_level \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(M, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_attention_matrix)\n\u001b[0;32m    180\u001b[0m masked_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(M_feature_level, x)\n\u001b[1;32m--> 181\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeat_transformers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m d \u001b[38;5;241m=\u001b[39m ReLU()(out[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_d])\n\u001b[0;32m    183\u001b[0m steps_output\u001b[38;5;241m.\u001b[39mappend(d)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:738\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    737\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared(x)\n\u001b[1;32m--> 738\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecifics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:780\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    777\u001b[0m     layers_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_glu)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m glu_id \u001b[38;5;129;01min\u001b[39;00m layers_left:\n\u001b[1;32m--> 780\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglu_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglu_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    781\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:804\u001b[0m, in \u001b[0;36mGLU_Layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m--> 804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim], torch\u001b[38;5;241m.\u001b[39msigmoid(x[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim :]))\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:36\u001b[0m, in \u001b[0;36mGBN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x_) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:155\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    157\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type='entmax', # \"sparsemax\"\n",
    "    n_d=64, # Set the hidden_dim to 64\n",
    "    n_a=64,\n",
    "    device_name='cuda'\n",
    ")\n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train=X_train.to_numpy(),\n",
    "    eval_set=[X_valid.to_numpy()],\n",
    "    pretraining_ratio=0.8,\n",
    ")\n",
    "\n",
    "unsupervised_model.save_model('tabnet_pretrainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_model = TabNetPretrainer()\n",
    "unsupervised_model.load_model('tabnet_pretrainer.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_encoder = unsupervised_model.network.encoder\n",
    "\n",
    "# # This is a torch module, use torch save to save this\n",
    "# torch.save({'model_state_dict': pretrained_encoder.state_dict(), 'model_architecture': str(pretrained_encoder)}, 'tabnet_pretrainer_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabNetPretraining(\n",
       "  (embedder): EmbeddingGenerator()\n",
       "  (masker): RandomObfuscator()\n",
       "  (encoder): TabNetEncoder(\n",
       "    (initial_bn): BatchNorm1d(141, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (initial_splitter): FeatTransformer(\n",
       "      (shared): GLU_Block(\n",
       "        (shared_layers): ModuleList(\n",
       "          (0): Linear(in_features=141, out_features=32, bias=False)\n",
       "          (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "        )\n",
       "        (glu_layers): ModuleList(\n",
       "          (0): GLU_Layer(\n",
       "            (fc): Linear(in_features=141, out_features=32, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): GLU_Layer(\n",
       "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (specifics): GLU_Block(\n",
       "        (glu_layers): ModuleList(\n",
       "          (0-1): 2 x GLU_Layer(\n",
       "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "            (bn): GBN(\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feat_transformers): ModuleList(\n",
       "      (0-2): 3 x FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (shared_layers): ModuleList(\n",
       "            (0): Linear(in_features=141, out_features=32, bias=False)\n",
       "            (1): Linear(in_features=16, out_features=32, bias=False)\n",
       "          )\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=141, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (specifics): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0-1): 2 x GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (att_transformers): ModuleList(\n",
       "      (0-2): 3 x AttentiveTransformer(\n",
       "        (fc): Linear(in_features=8, out_features=141, bias=False)\n",
       "        (bn): GBN(\n",
       "          (bn): BatchNorm1d(141, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (selector): Entmax15()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TabNetDecoder(\n",
       "    (feat_transformers): ModuleList(\n",
       "      (0-2): 3 x FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (shared_layers): ModuleList(\n",
       "            (0): Linear(in_features=8, out_features=16, bias=False)\n",
       "          )\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=8, out_features=16, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(16, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (specifics): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=8, out_features=16, bias=False)\n",
       "              (bn): GBN(\n",
       "                (bn): BatchNorm1d(16, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reconstruction_layer): Linear(in_features=8, out_features=141, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unsupervised_model.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Representations: torch.Size([10, 8])\n",
      "Feature Importances (M_loss): tensor(-0.4954)\n"
     ]
    }
   ],
   "source": [
    "# Define the custom encoder class\n",
    "class CustomTabNetEncoder(torch.nn.Module):\n",
    "    def __init__(self, pretrainer_model):\n",
    "        super(CustomTabNetEncoder, self).__init__()\n",
    "        self.encoder = pretrainer_model.network.encoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass data through the encoder to get the step outputs and feature importances\n",
    "        steps_output, M_loss = self.encoder(x)\n",
    "        final_step_output = steps_output[-1]\n",
    "        return final_step_output, M_loss\n",
    "\n",
    "# Initialize the encoder with the pre-trained model\n",
    "encoder = CustomTabNetEncoder(unsupervised_model)\n",
    "encoder.eval()  # Set the encoder to evaluation mode\n",
    "\n",
    "# Move the encoder to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder.to(device)\n",
    "\n",
    "# Create random tensor\n",
    "random_data = torch.randn(10, 141)  # 10 samples, 141 features each\n",
    "\n",
    "# Move the random tensor to the device\n",
    "random_data_tensor = random_data.to(device).to(torch.float32)\n",
    "\n",
    "# Encode the random data\n",
    "with torch.no_grad():\n",
    "    latent_representations, feature_importances = encoder(random_data_tensor)\n",
    "\n",
    "# Print the outputs\n",
    "print(\"Latent Representations:\", latent_representations.shape)\n",
    "print(\"Feature Importances (M_loss):\", feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample of random data: tensor([ 1.2233, -0.1336,  2.4271,  0.7167, -1.7371, -0.3371, -1.8067, -1.7551,\n",
      "         1.9278,  0.6380, -1.3735, -0.1758, -0.4896, -0.8453, -0.1855, -1.1828,\n",
      "        -0.7313, -0.1734,  1.0634, -1.1755, -0.3373,  1.5613,  0.3157,  0.3237,\n",
      "        -1.5060, -0.1666,  0.2775, -0.3152,  0.4184, -0.3998,  0.9849, -0.4676,\n",
      "        -0.8584, -1.8549,  0.1904,  0.2829, -0.6988,  0.0996, -0.8062, -0.0351,\n",
      "        -0.3407,  1.6213,  0.7040, -0.1762, -0.3581, -0.1252, -1.0481, -0.7461,\n",
      "        -2.1339, -2.3023,  0.3318,  0.6340, -0.6067, -2.2478,  0.8009, -0.2119,\n",
      "         1.1917,  0.4351,  0.7897,  1.7413,  0.8892, -0.2036,  0.0980, -0.3547,\n",
      "        -0.1185, -0.4851, -0.8448, -0.1437, -0.4034,  0.6374,  0.3527, -0.5134,\n",
      "        -0.3074,  2.7839,  0.3000,  0.6985,  0.7986, -2.2435, -0.3787, -1.2733,\n",
      "         0.7195, -1.5267, -0.1683,  0.5944,  1.1460,  2.5657,  0.6367, -0.0327,\n",
      "        -0.3165, -0.1675,  1.7093,  0.9208,  0.5436,  1.1848,  0.1269,  0.5602,\n",
      "         1.3563, -0.4943,  2.7827,  0.0366,  0.4367, -2.2673,  1.1585, -1.7429,\n",
      "         0.0481, -0.2709, -0.8047,  1.4798, -0.8851,  1.0296,  1.0478,  0.5181,\n",
      "        -1.2217,  0.0412, -0.5600, -0.7218, -2.6030, -0.1586, -1.3461, -0.0675,\n",
      "         0.7156,  2.0541, -0.6534, -1.8072,  0.8914,  1.2339, -0.1113, -0.7501,\n",
      "         0.3875, -0.4450, -0.9243, -0.1716,  0.5118,  1.4997, -0.7307, -0.1946,\n",
      "         0.0772, -0.4423, -0.2390,  0.2167,  0.1774])\n",
      "\n",
      "First sample in latent representations: tensor([  0.0000,  50.5927,   0.0000, 248.4428,   0.0000,  96.9490,   0.0000,\n",
      "         99.2174])\n"
     ]
    }
   ],
   "source": [
    "# Test the first batch\n",
    "print(f\"First sample of random data: {random_data[0]}\\n\")\n",
    "print(f\"First sample in latent representations: {latent_representations[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC Output: tensor([[0.1616, 0.0825, 0.5165, 0.0000, 0.3087, 1.5011, 1.6584, 0.0000],\n",
      "        [0.1617, 0.0858, 0.4999, 0.0000, 0.3056, 1.5118, 1.6642, 0.0000],\n",
      "        [0.1612, 0.0841, 0.5074, 0.0000, 0.3134, 1.5108, 1.6724, 0.0000],\n",
      "        [0.1644, 0.0806, 0.5248, 0.0000, 0.3048, 1.4918, 1.6454, 0.0000],\n",
      "        [0.0000, 1.2509, 0.0000, 4.8240, 0.0000, 3.1320, 0.0000, 0.0000],\n",
      "        [2.9493, 0.0000, 0.0000, 0.0000, 0.0000, 2.9895, 5.4178, 3.5081],\n",
      "        [0.1662, 0.0799, 0.5275, 0.0000, 0.3028, 1.4882, 1.6398, 0.0000],\n",
      "        [0.0000, 0.1215, 0.5363, 0.4715, 0.3683, 1.3670, 0.9770, 0.0000],\n",
      "        [0.1673, 0.0811, 0.5206, 0.0000, 0.3037, 1.4936, 1.6460, 0.0000],\n",
      "        [0.0350, 0.0483, 0.7495, 0.0239, 0.3506, 1.3797, 1.4839, 0.0000]])\n",
      "Feature Importances: tensor(-0.8036)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example random data: 10 samples, 141 features each\n",
    "random_data = torch.randn(10, 141)  # 10 samples, 20 features each\n",
    "\n",
    "# Move the random tensor to the device\n",
    "random_data_tensor = random_data.to(device).to(torch.float32)\n",
    "\n",
    "# Encode the random data\n",
    "with torch.no_grad():\n",
    "    fc_output, feature_importances = encoder(random_data_tensor)\n",
    "\n",
    "# Print the outputs\n",
    "print(\"FC Output:\", fc_output)\n",
    "print(\"Feature Importances:\", feature_importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain with VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim * 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        \n",
    "        # Clamp logvar to prevent numerical instability\n",
    "        logvar = torch.clamp(logvar, min=-10, max=2)  # Adjust as necessary\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_recon, mu, logvar = self.forward(x)\n",
    "\n",
    "        # Diagnostics: Check for NaNs in logvar\n",
    "        if torch.isnan(logvar).any():\n",
    "            print(\"NaN detected in logvar\")\n",
    "        \n",
    "        # Add a small value to logvar to prevent numerical issues\n",
    "        logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "        \n",
    "        recon_loss = nn.functional.mse_loss(x_recon, x, reduction='sum')\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = recon_loss + kl_loss\n",
    "        print(loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "vae_model = VAE(input_dim = X_test.shape[1], hidden_dim = 128, latent_dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1301.0930,  3075.4138,  7214.8564,  ...,  4246.9800,  2207.7947,\n",
      "           467.3550],\n",
      "        [ 1112.5470,  2620.4551,  6194.1484,  ...,  3626.0054,  1878.1315,\n",
      "           392.9468],\n",
      "        [ 1852.4546,  4418.6499, 10413.0918,  ...,  6097.6167,  3141.7329,\n",
      "           657.8369],\n",
      "        ...,\n",
      "        [ 1781.8385,  4273.2471, 10055.7354,  ...,  5894.2725,  3029.8838,\n",
      "           637.3226],\n",
      "        [  603.0688,  1442.4968,  3378.1577,  ...,  1989.8705,  1032.0741,\n",
      "           211.5147],\n",
      "        [ 2217.4011,  5287.3174, 12433.1357,  ...,  7292.9141,  3765.7244,\n",
      "           800.4923]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([32, 141])\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(train_loader))[0]  # Get the first batch of x\n",
    "optimizer.zero_grad()  # Zero the gradients\n",
    "output, _, _ = vae_model(x)  # Forward pass through the VAE model\n",
    "print(output)\n",
    "print(output.shape)  # Print the shape of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,_,_ = vae_model(torch.randn(20, 141))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2007, -0.1785, -0.1725,  ...,  0.1502, -0.3017,  0.2442],\n",
       "        [ 0.0374, -0.4537,  0.0973,  ...,  0.2426, -0.3924,  0.3847],\n",
       "        [ 0.1518,  0.5820, -0.1057,  ..., -0.1026,  0.1041,  0.4677],\n",
       "        ...,\n",
       "        [ 0.2070,  0.0596,  0.4023,  ...,  0.0873, -0.1273,  0.1061],\n",
       "        [ 0.0619,  0.3165, -0.0754,  ...,  0.2179, -0.2738, -0.0085],\n",
       "        [ 0.0036,  0.0472,  0.2800,  ...,  0.3336, -0.2945,  0.0604]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=141, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=141, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Batch [0/33733], Loss: 23663749365760.0\n",
      "Epoch [1/100], Batch [2500/33733], Loss: 437954304.0\n",
      "Epoch [1/100], Batch [5000/33733], Loss: 598092544.0\n",
      "Epoch [1/100], Batch [7500/33733], Loss: 239597344.0\n",
      "Epoch [1/100], Batch [10000/33733], Loss: 8406275584.0\n",
      "Epoch [1/100], Batch [12500/33733], Loss: 142291008.0\n",
      "Epoch [1/100], Batch [15000/33733], Loss: 1895530112.0\n",
      "Epoch [1/100], Batch [17500/33733], Loss: 787751232.0\n",
      "Epoch [1/100], Batch [20000/33733], Loss: 174201504.0\n",
      "Epoch [1/100], Batch [22500/33733], Loss: 119082104.0\n",
      "Epoch [1/100], Batch [25000/33733], Loss: 500142464.0\n",
      "Epoch [1/100], Batch [27500/33733], Loss: 773646912.0\n",
      "Epoch [1/100], Batch [30000/33733], Loss: 282062720.0\n",
      "Epoch [1/100], Batch [32500/33733], Loss: 94347912.0\n",
      "Epoch 1, Average Loss: 518535074.2554273\n",
      "Epoch [2/100], Batch [0/33733], Loss: 66117192.0\n",
      "Epoch [2/100], Batch [2500/33733], Loss: 81347680.0\n",
      "Epoch [2/100], Batch [5000/33733], Loss: 112149480.0\n",
      "Epoch [2/100], Batch [7500/33733], Loss: 2984604672.0\n",
      "Epoch [2/100], Batch [10000/33733], Loss: 43004516.0\n",
      "Epoch [2/100], Batch [12500/33733], Loss: 46021372.0\n",
      "Epoch [2/100], Batch [15000/33733], Loss: 88838960.0\n",
      "Epoch [2/100], Batch [17500/33733], Loss: 40360432.0\n",
      "Epoch [2/100], Batch [20000/33733], Loss: 36939728.0\n",
      "Epoch [2/100], Batch [22500/33733], Loss: 78372032.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 28\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Log loss at intervals\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "latent_dim = 64\n",
    "vae_model = VAE(input_dim = X_test.shape[1], hidden_dim = 128, latent_dim = 64)\n",
    "optimizer = torch.optim.Adam(vae_model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Training loop\n",
    "vae_model.train()\n",
    "num_epochs = 100\n",
    "log_interval = 2500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x,y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        x_recon, _, _ = vae_model(x)  # Forward pass\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        recon_loss = criterion(x_recon, x)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = recon_loss #+ kl_loss\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Log loss at intervals\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}')\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Average Loss: {epoch_loss / len(train_loader.dataset)}')\n",
    "\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoder\n",
    "encoder = vae_model.encoder\n",
    "torch.save(encoder.state_dict(), 'vae_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
