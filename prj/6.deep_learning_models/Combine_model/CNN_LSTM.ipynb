{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import lime\n",
    "import os\n",
    "# from joblib import dump\n",
    "import joblib\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.metrics import MeanSquaredError, MeanAbsoluteError, RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import wandb\n",
    "warnings.filterwarnings('ignore')\n",
    "# import dask.dataframe as dd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/exp\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dir='../../../styles'\n",
    "plt.style.use(f'{style_dir}/style.mplstyle')\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"enefit_prediction_consumer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays=1\n",
    "X=pd.read_csv(f'{save_dir}/X_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "y=pd.read_csv(f'{save_dir}/y_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "X_train=pd.read_csv(f'{save_dir}/X_train_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "X_valid=pd.read_csv(f'{save_dir}/X_valid_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "y_train=pd.read_csv(f'{save_dir}/y_train_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "y_valid=pd.read_csv(f'{save_dir}/y_valid_train_lag{ndays}_pre_processing.csv', index_col=None)\n",
    "scaler_y=joblib.load(f'{save_dir}/scaler_y.pkl')\n",
    "best_params = dict(np.load(f'{save_dir}/best_params_.npz',allow_pickle=True))\n",
    "target_valid=pd.read_csv(f'{save_dir}/target_valid{ndays}_pre_processing.csv', index_col=None)\n",
    "target_valid.drop(columns=['Unnamed: 0'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "X_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "X_valid.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_valid.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                mode='min',\n",
    "    min_delta=0.00005,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=6,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',  # Đường dẫn để lưu model\n",
    "    monitor='val_loss',  # Theo dõi val_loss\n",
    "    mode='min',\n",
    "    save_best_only=True,  # Lưu lại chỉ model có val_loss tốt nhất\n",
    "    verbose=1,  # Hiển thị thông báo khi lưu model\n",
    "    save_format=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoding:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.feature = None\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        x = Conv1D(32, 3, activation='relu')(inputs)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(64, activation='relu')(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        self.feature = Dense(16, activation='relu')(x)\n",
    "        model = Model(inputs, self.feature, name='model1')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassification:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        x = LSTM(units=50)(inputs)  # Adjust units and other parameters as needed\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(units=50, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        outputs = Dense(units=1, activation='linear')(x)\n",
    "        model = Model(inputs, outputs, name='model2')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineModel:\n",
    "    def __init__(self, input_shape,encoder, classification, lr=0.0001):\n",
    "        self.input_shape = input_shape\n",
    "        self.model1 = encoder\n",
    "        self.feature_shape = (len(encoder.features),)\n",
    "        self.model2 = classification\n",
    "        self.lr = lr\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        combined_input = self.model1.model.input\n",
    "        combined_feature = self.model1.model.output\n",
    "        combined_output = self.model2.model(combined_feature)\n",
    "        combined_model = Model(inputs=combined_input, outputs=combined_output, name='combined_model')\n",
    "        combined_model.compile(optimizer=Adam(learning_rate=self.lr), loss='mae', metrics=['mae'])\n",
    "        return combined_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
