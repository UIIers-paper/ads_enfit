{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold, cross_val_score, train_test_split\n","from sklearn.metrics import make_scorer, mean_absolute_error, r2_score\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","import lightgbm as lgb\n","import shap\n","import lime\n","import dask.dataframe as dd\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_dir=\"../../exps\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df = pd.read_csv(f'{save_dir}/train_lag1_pre_processing.csv')\n","\n","df = dd.read_csv(f'{save_dir}/train_lag1_pre_processing.csv')\n","df = df.compute() "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df.drop('target', axis=1)\n","y = df['target']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","num_folds = 5\n","seed = 7\n","scorers = {'mae': make_scorer(mean_absolute_error), 'r2': make_scorer(r2_score)}\n","models = []\n","\n","# Defining models\n","models.append(('LR', LinearRegression()))\n","models.append(('Ridge', Ridge(alpha=1.0)))\n","models.append(('Lasso', Lasso(alpha=0.1)))\n","models.append(('SVR', SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)))\n","models.append(('DT', DecisionTreeRegressor(random_state=42)))\n","models.append(('RF', RandomForestRegressor(n_estimators=100, random_state=42)))\n","models.append(('GBR', GradientBoostingRegressor(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)))\n","models.append(('LGBM', lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.1, n_estimators=100)))\n","\n","# Function to evaluate models\n","def check_model(name, model, X, y, scoring):\n","    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n","    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n","    msg = f\"{scoring} {name}: {cv_results.mean():.3f} ({cv_results.std():.3f})\"\n","    print(msg)\n","    return cv_results\n","\n","results_mae = []\n","names_mae = []\n","results_r2 = []\n","names_r2 = []\n","\n","# Evaluating models\n","for name, model in models:\n","    print(f\"Evaluating {name}...\")\n","    mae_result = check_model(name, model, X, y, scoring='neg_mean_absolute_error')\n","    results_mae.append(mae_result)\n","    names_mae.append(name)\n","    \n","    r2_result = check_model(name, model, X, y, scoring='r2')\n","    results_r2.append(r2_result)\n","    names_r2.append(name)\n","\n","# Plotting MAE\n","fig_mae = plt.figure()\n","fig_mae.suptitle('Comparison of MAE among models')\n","ax_mae = fig_mae.add_subplot(111)\n","plt.boxplot(results_mae)\n","ax_mae.set_xticklabels(names_mae)\n","plt.ylabel('MAE')\n","plt.show()\n","\n","# Plotting R2\n","fig_r2 = plt.figure()\n","fig_r2.suptitle('Comparison of R2 among models')\n","ax_r2 = fig_r2.add_subplot(111)\n","plt.boxplot(results_r2)\n","ax_r2.set_xticklabels(names_r2)\n","plt.ylabel('R2 Score')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train Decision Tree model\n","dt_model = DecisionTreeRegressor(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["importances = dt_model.feature_importances_\n","indices = np.argsort(importances)[::-1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Feature ranking:\")\n","for f in range(X_train.shape[1]):\n","    print(f\"{f + 1}. feature {X_train.columns[indices[f]]} ({importances[indices[f]]})\")\n","\n","# Visualize Decision Tree\n","plt.figure(figsize=(20,10))\n","plot_tree(dt_model, feature_names=X_train.columns, filled=True, rounded=True)\n","plt.title(\"Decision Tree Structure\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train LightGBM model\n","lgbm_model = lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.1, n_estimators=100)\n","lgbm_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluating SHAP for Decision Tree\n","explainer_dt = shap.Explainer(dt_model, X_train)\n","shap_values_dt = explainer_dt(X_test)\n","\n","# Evaluating SHAP for LightGBM\n","explainer_lgbm = shap.Explainer(lgbm_model, X_train)\n","shap_values_lgbm = explainer_lgbm(X_test)\n","\n","# Evaluating LIME for Decision Tree\n","lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, verbose=True, mode='regression')\n","lime_exp_dt = lime_explainer.explain_instance(X_test.iloc[0].values, dt_model.predict)\n","\n","# Evaluating LIME for LightGBM\n","lime_exp_lgbm = lime_explainer.explain_instance(X_test.iloc[0].values, lgbm_model.predict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# SHAP summary plot for Decision Tree\n","shap.summary_plot(shap_values_dt, X_test, plot_type=\"bar\", title=\"SHAP Decision Tree Feature Importance\")\n","\n","# SHAP summary plot for LightGBM\n","shap.summary_plot(shap_values_lgbm, X_test, plot_type=\"bar\", title=\"SHAP LightGBM Feature Importance\")\n","\n","# LIME explanation for Decision Tree\n","lime_exp_dt.show_in_notebook()\n","\n","# LIME explanation for LightGBM\n","lime_exp_lgbm.show_in_notebook()\n","\n","\n","# Detailed force plot for one sample in the test set\n","shap.force_plot(explainer_dt.expected_value, shap_values_dt[0,:], X_test.iloc[0,:], matplotlib=True)\n","shap.force_plot(explainer_lgbm.expected_value, shap_values_lgbm[0,:], X_test.iloc[0,:], matplotlib=True)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
